# ML from Scratch to Production

An end-to-end **Machine Learning engineering and MLOps project** that demonstrates
how to design, train, validate, and operationalize a machine learning model using
**industry-standard, production-oriented ML practices**.

The project uses the **California Housing dataset** as a reference use case and
focuses on building a **reproducible, maintainable, and deployment-ready ML system**
â€” progressing from experimentation to production pipelines.

---

## ğŸ¯ Project Objective

The objectives of this project are to:

- Engineer a regression model **from first principles**
- Follow a **structured ML lifecycle** from data understanding to validation
- Establish a **validated baseline model**
- Migrate notebook-based experimentation into **production-grade Python pipelines**
- Build the foundation for a **full MLOps workflow** (CI/CD, tracking, deployment)

---

## ğŸ§  Machine Learning Phase (Completed)

The ML phase was implemented using a **progressive, evidence-driven approach**, where
each modeling decision was backed by quantitative evaluation.

### 1ï¸âƒ£ Problem Framing & Data Understanding
- Defined prediction target: `median_house_value`
- Dataset and feature analysis
- Identification of numerical vs categorical features
- Constraints and data quality considerations

### 2ï¸âƒ£ Baseline Modeling
- Linear Regression
- Ridge Regression
- Used to diagnose bias, variance, and scaling behavior

### 3ï¸âƒ£ Non-Linear Modeling
- Decision Trees (unconstrained & constrained)
- Random Forest for variance reduction and stability

### 4ï¸âƒ£ Feature Engineering
- Domain-driven engineered features:
  - Rooms per household
  - Bedrooms per room
  - Population per household
- Systematic evaluation across model families

### 5ï¸âƒ£ Advanced Modeling
- Gradient Boosting using `HistGradientBoostingRegressor`
- Selected after Random Forest performance plateaued
- Improved biasâ€“variance tradeoff

### 6ï¸âƒ£ Model Validation
- Hold-out test evaluation
- Cross-validation for stability
- Metrics: RMSE and RÂ²

ğŸ‘‰ **Gradient Boosting with engineered features is selected as the current production baseline.**

---

## ğŸ“Š Current Best Model

| Model | Test RMSE (â‰ˆ) | CV RMSE (â‰ˆ) | Notes |
|------|---------------|------------|------|
| Random Forest | ~49k | ~49k | Stable non-linear baseline |
| Gradient Boosting | **~45.5k** | **~46.5k** | Lower bias, improved generalization |

Cross-validation confirms consistent generalization across data splits.

---

## âš™ï¸ Production Pipelines (Completed)

Notebook experimentation has been **fully migrated to production-grade pipelines**.

### âœ… Training Pipeline
- Deterministic data splitting
- Feature preprocessing (imputation, encoding, feature engineering)
- Model training and evaluation
- Artifact persistence (model, preprocessors, metrics)
- Structured logging

### âœ… Batch Inference Pipeline
- Loads production artifacts
- Applies identical preprocessing as training
- Runs predictions on curated inference inputs
- Outputs predictions separately from model artifacts

These pipelines are designed to be:
- CI/CD friendly
- Reproducible
- API-ready

---

## ğŸ—‚ï¸ Repository Structure

```

CaliforniaHousePricePred
â”œâ”€â”€ artifacts/
â”‚   â”œâ”€â”€ experiments/         # Notebook experiment outputs (history)
â”‚   â””â”€â”€ production/          # Single source of truth for deployment
â”œâ”€â”€ data/
â”‚   â”œâ”€â”€ raw/                 # Original dataset
â”‚   â””â”€â”€ inference/           # Curated inference inputs
â”œâ”€â”€ docs/                    # Design decisions & ML reasoning
â”œâ”€â”€ notebooks/               # Exploratory ML experimentation
â”œâ”€â”€ pipelines/               # Training & inference execution entry points
â”œâ”€â”€ src/                     # Reusable production ML code
â”œâ”€â”€ outputs/                 # Inference outputs (ephemeral)
â”œâ”€â”€ logs/                    # Pipeline execution logs
â”œâ”€â”€ requirements.txt
â””â”€â”€ README.md

```

---

## ğŸ“„ Documentation Philosophy

- **Notebooks** â†’ exploration and experimentation
- **Docs** â†’ reasoning, decisions, and conclusions
- **Pipelines** â†’ execution and orchestration
- **Source code** â†’ reusable, testable ML components
- **Artifacts** â†’ immutable, versioned model outputs
- **Outputs** â†’ ephemeral inference results

---

## ğŸš€ MLOps Phase (Next)

The next phase focuses on **serving and automation**:

- FastAPI-based online inference
- CI/CD integration for training and inference pipelines
- MLflow experiment tracking and model registry
- Championâ€“challenger model promotion
- Monitoring and retraining strategies

The current pipelines serve as a **stable and production-ready foundation** for
these MLOps components.

---

## ğŸ§© Design Principles

- Sequential ML development (baseline â†’ validation â†’ improvement)
- Clear separation of experimentation and production code
- Reproducibility and traceability at every stage
- Evidence-based model selection
- Infrastructure-agnostic ML design

---

## ğŸ“Œ Summary

This repository demonstrates how to evolve a machine learning project from
notebook-based experimentation into a **clean, maintainable, and production-ready
ML system**, following real-world ML engineering and MLOps best practices.

