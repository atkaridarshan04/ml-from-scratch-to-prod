---
apiVersion: serving.kserve.io/v1beta1
kind: InferenceService
metadata:
  name: housing-model
  annotations:
    serving.kserve.io/s3-endpoint: s3.ap-south-1.amazonaws.com
    serving.kserve.io/s3-usehttps: "1"
spec:
  predictor:
    serviceAccountName: s3-sa
    model:
      modelFormat:
        name: mlflow
      protocolVersion: v2
      runtime: kserve-mlserver
      storageUri: "s3://mlflow-artifact-store-123-da/1/models/m-493f9d5f4c0e4a3ebc60d7789d752895/artifacts"
      # resources:
      #   requests:
      #     cpu: "100m"
      #     memory: "512Mi"
      #   limits:
      #     cpu: "1"
      #     memory: "1Gi"